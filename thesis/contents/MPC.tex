\subsection{Model Predictive Control}
\label{sec: MPC}
Model predictive control~(MPC) is an advanced method of feedback control that is used to control a system while satisfying a set of constraints on the input and/or the state. It offers several advantages over the infinite horizon LQR; to list a few, the input is computed over a receding finite time horizon, i.e., at each time step, an optimal control input vector is computed by minimizing a user-specified cost function (e.g., energy or tracking error) over a predefined time horizon $N_p$, and only the first value of this input vector is applied to progress the system to the next time step where the entire process is repeated, thereby enabling optimal tracking of the reference trajectory.  Although this appears as a computationally expensive process, which it is when compared to the LQR, it performs a whole lot better in the event of any external disturbances or sudden changes in reference trajectory. This is especially advantageous in tracking problems where the controller is able to `predict' any setpoint changes and react accordingly. Consequently, this also means that the controller can predict and provide early warnings of any potential problems. Also, any constraints on input and output can be imposed in a simple way in this technique.\par
For this thesis, the state-space form of MPC is considered. There is abundant literature available describing the construction and implementation of the MPC; the reader is encouraged to refer \cite{MPCbook} for a detailed explanation of the MPC. This section will therefore only briefly explain the cost function used in this thesis and an approach explored in Korda et al. \cite{MPC_Korda} to eliminate the dependence of the cost function on the dimension of state of the system which will eventually prove useful for formulating the MPC for high-dimensional systems. \par 
The following formulations are an adaptation of the formulations presented in \cite{MPC_Korda}.\\
Assume a nonlinear system of the form $\mathbf{x}_{k+1} = f(\mathbf{x}_k,\mathbf{u}_k)$ can be approximated in terms of a linear model of the form,
\begin{equation}
\label{eq:MPCdisc}
    \mathbf{x}_{k+1} = \mathbf{Ax}_k + \textbf{Bu}_k \:,
\end{equation}
The model predictive controller solves at each time step $k$ of the closed-loop iteration the optimization problem, 
\begin{equation}
  \label{eq:MPCoptim}
  \begin{alignedat}{3}
&\min_{\mathbf{u}_{i},\mathbf{x}_{i}} && J\left((\mathbf{u}_{i})_{i=0}^{N_p-1}, (\mathbf{x}_{i})_{i=0}^{N_p-1}\right) && \\
&\textup{subject to} \quad &&\mathbf{x}_{i+1}  = \mathbf{Ax}_{i} + \textbf{Bu}_{i} \:, && i = 0,1,\dots,N_p-1\\
& &&\mathbf{E}_{i}\mathbf{x}_{i} + \mathbf{F}_{i}\mathbf{u}_{i} \leq \mathbf{b}_{i} \;, &&  i = 0,1,\dots,N_p-1\\
& &&\mathbf{E}_{N_p}\mathbf{x}_{N_p} \leq \mathbf{b}_{N_p} \;, &&\\
&\textup{parameter} && \mathbf{x}_0 = \mathbf{x}_k \;, &&   
\end{alignedat}
\end{equation}

where the matrices $\mathbf{E}_{i} \in \mathbb{R}^{n_c \times n}$, $\mathbf{F}_{i} \in \mathbb{R}^{n_c \times m}$ define the state and input polyhedral constraints, respectively and $\mathbf{b}_{i} \in \mathbb{R}^{n_c}$ is the vector of constraints, and the convex quadratic cost function $J$ is given by,
\begin{equation}
\label{eq:MPCcostfunction}
    J = \mathbf{x}_{N_p}^\top \mathbf{Q}_{N_p} \mathbf{x}_{N_p} + \sum_{i=0}^{N_p-1} \mathbf{x}_{i}^\top \mathbf{Q} \mathbf{x}_{i} + \mathbf{u}_{i}^\top \mathbf{R}\mathbf{u}_{i} \;,
\end{equation}
% 
where $\mathbf{x}_{N_p}$ is the final state at time instance $N_p$, $\mathbf{Q}_{N_p} \in \mathbb{R}^{n \times n}$ is the corresponding penalty on the final state.
\par 
The optimization problem (\ref{eq:MPCoptim}) parametrized by the current state of the nonlinear dynamical system $\mathbf{x}_k$ then defines a feedback controller $F\mathbf{(x)} = \mathbf{u_0}^\ast(\mathbf{x}_k)$, where $\mathbf{u_0}^\ast(\mathbf{x}_k)$ is the optimal solution to the optimization problem.\par
It is always beneficial to eliminate the dependence of the optimization problem on the dimension of the state $n$. Consequently, the computational complexity of solving the optimization problem will be rendered independent of the dimension $n$. This is especially useful when dealing with the approximation of nonlinear systems through the Koopman operator theory, where the state might be $\textit{lifted}$ to a higher dimension which results in a linear dynamical system that approximates the nonlinear dynamical system. This elimination can be achieved by formulating the dynamics in the following way: consider the discrete-time or the \textit{one step-ahead predictor} state-space model
\begin{align}
\label{Eq: predicteqns}
\begin{split}
    \mathbf{x}_{k+1} &= \mathbf{Ax}_k + \mathbf{B}\mathbf{u}_k \quad \quad \mathbf{x}(0) = \mathbf{x}_0\;, \\
    \mathbf{y}_k &= \mathbf{C}\mathbf{x}_k \;,
\end{split}
\end{align}
where $\mathbf{x}_{k+1} \in \mathbb{R}^{n}$ is the `future' value of the current state $\mathbf{x}_k$ at a time instance $k = [0,1,2,\dots,N_p-1]$, $\mathbf{u}_k \in \mathbb{R}^m$ is the input at time instance $k$ and $\mathbf{A} \in \mathbb{R}^{n\times n},\mathbf{B} \in \mathbb{R}^{n \times m} ~ \textup{and}~ \mathbf{C} \in \mathbb{R}^{l \times n} $ are the system, input and output matrices, respectively. Naturally, the state at time instance $k+2$ can then be predicted from Eq.~\ref{Eq: predicteqns} as
% 
\begin{equation}
\label{eq:predicteqns2}
    \mathbf{x}_{k+2} = \mathbf{Ax}_{k+1} + \mathbf{B}\mathbf{u}_{k+1} \;,
\end{equation}
% 
Subsituting Eq.~\ref{Eq: predicteqns} in Eq.~\ref{eq:predicteqns2}, the future state at the second time instance can be obtained in the terms of the initial state $\mathbf{x}_k$ as
% 
\begin{equation}
    \mathbf{x}_{k+2} = \mathbf{A}^2\mathbf{x}_{k} + \mathbf{AB}\mathbf{u}_{k} + \mathbf{B}\mathbf{u}_{k+1} \;.
\end{equation}
% 
The one-step ahead predictor model therefore, can be used recursively to predict the evolution of state for the next $N_p$ steps of interest where $N_p$ is the time interval over which a cost function is evaluated to compute the optimal input corresponding to the desired state evolution in that time interval.
% 
\begin{equation}
\label{eq: Nstep}
    \underbrace{\begin{bmatrix}
    \mathbf{x}_{k+1} \\
    \mathbf{x}_{k+2}\\
    \vdots\\
    \mathbf{x}_{k+N_p} 
    \end{bmatrix}}_{\mathbf{X}_{k+1}} = \underbrace{\begin{bmatrix}
    \mathbf{A}\\
    \mathbf{A}^2\\
    \vdots\\
    \mathbf{A}^{N_p}
    \end{bmatrix}}_{\mathbf{\bar{A}}}~\mathbf{x}_k + \underbrace{\begin{bmatrix}
    \mathbf{B} & \mathbf{0} & \dots & \mathbf{0}\\
    \mathbf{AB} & \mathbf{B} & \dots & \mathbf{0}\\
    \vdots & \vdots & \dots & \vdots\\ 
    \mathbf{A}^{N_p-1}\mathbf{B} & \mathbf{A}^{N_p-2}\mathbf{B} & \dots & \mathbf{B}\\
    \end{bmatrix}}_{\mathbf{\bar{B}}} ~ \underbrace{\begin{bmatrix}
    \mathbf{u}_k \\
    \mathbf{u}_{k+1}\\
    \vdots\\
    \mathbf{u}_{k+N_p-1}
    \end{bmatrix}}_{\mathbf{U}_k}\;.
\end{equation}
% 
Eq.~\ref{eq: Nstep} can be compactly written as,
% 
\begin{equation}
    \label{eq:NstepComp}
    \mathbf{X}_{k+1} = \mathbf{\bar{A}x}_k + \mathbf{\bar{B}}\mathbf{U}_k \;,
\end{equation}
% 
where $\mathbf{X}_{k+1} \in \mathbb{R}^{N_pn}$ is the vector of state predictions, $\mathbf{\bar{A}} \in \mathbb{R}^{N_pn\times n}$, $\mathbf{\bar{B}} \in \mathbb{R}^{N_pn\times N_pn}$ is a Toeplitz matrix~(or a diagonal-constant matrix) and $\mathbf{U}_k \in \mathbb{R}^{N_pm}$ is the vector of predicted sequence of control inputs. Note that Eq.~\ref{eq:NstepComp} depends only on the initial state $\mathbf{x}_0$ and the sequence of control inputs $\mathbf{U}_k$.\par
Consequently, the output equation is
% 
\begin{equation}
\label{eq:Nstepout}
    \mathbf{Y}_{k+1} = \mathbf{\bar{C}}\mathbf{\bar{A}x}_k + \mathbf{\bar{C}}\mathbf{\bar{B}U}_k \;, 
\end{equation}
% 
where $\mathbf{Y}_{k+1} \in \mathbb{R}^{N_pl}$ is the vector of predicted future outputs and $\mathbf{\bar{C}} \in \mathbb{R}^{N_pl\times N_pn}$ is the computed as the Kronecker product $\mathbf{I}_{N_p} \otimes \mathbf{C}$. Note that the notations used in this section, $\mathbf{\bar{A},\bar{B},\bar{C}}$ correspond to the notations $\mathbf{A_b, B_b, C_b}$ used in the Matlab script.
\par
It is then possible to transform the optimization problem (\ref{eq:MPCoptim}) to the so-called \textit{dense form}
\begin{equation}
\label{eq:MPCdense}
\begin{alignedat}{2}
        &\min_{\mathbf{U} \in \mathbb{R}^{mN_p}} \quad && \mathbf{U}^\top\mathbf{H}\mathbf{U} +  \mathbf{x}_0^\top\mathbf{G}\mathbf{U} \\
        & \textup{subject to}\quad && \mathbf{L}\mathbf{U} + \mathbf{M}\mathbf{x}_0 \leq \mathbf{c} \\
        ~ & \textup{parameter} && \mathbf{x}_0 = \mathbf{x}_k
        % \mathbf{h}^\top\mathbf{U} +
\end{alignedat}    
\end{equation}
for some positive-definite matrix, the \textit{Hessian} $\mathbf{H} \in \mathbb{R}^{mN_p \times mN_p}$ and some matrices, $\mathbf{G} \in \mathbb{R}^{n \times mN_p}$, $\mathbf{L} \in \mathbb{R}^{n_cN_p \times mN_p}$, $\mathbf{M} \in \mathbb{R}^{n_cN_p \times n}$ and vector of constraints $\mathbf{c} \in \mathbb{R}^{n_cN_p}$. The matrices are defined as
\begin{equation}
    \begin{alignedat}{5}
    &\mathbf{H} && = \mathbf{\bar{R}} + \mathbf{\bar{B}}^\top\mathbf{\bar{Q}}\mathbf{\bar{B}} \;, \quad &&\mathbf{G} && = 2\mathbf{\bar{A}}^\top\mathbf{\bar{Q}}\mathbf{\bar{B}}\;, && \\
    & \mathbf{L} &&= \mathbf{\bar{F}} + \mathbf{\bar{E}\bar{B}}\;, && \mathbf{M} && = \mathbf{\bar{E}\bar{A}} \;,&& \mathbf{c} &&= [\mathbf{b}_0^\top,\dots,\mathbf{b}_{N_p}^\top]^\top
    % \mathbf{h} &&= \mathbf{\bar{B}}^\top\mathbf{q} + \mathbf{r} \;, \quad && 
    \end{alignedat}
\end{equation}
where $\mathbf{\bar{Q}} = \mathbf{I}_{N_p} \otimes \mathbf{Q}  ~\in \mathbb{R}^{nN_p \times nN_p}$, $\mathbf{\bar{R}} = \mathbf{I}_{N_p} \otimes \mathbf{R} ~ \in \mathbb{R}^{N_pm \times N_pm}$, $\mathbf{E} = \mathbf{I}_{N_p} \otimes \mathbf{E}  ~\in \mathbb{R}^{n_cN_p \times n_cN_p}$, and
\begin{equation*}
    \mathbf{\bar{F}} = \begin{bmatrix}
    F_0 & 0 & ~ \dots ~ & 0 \\
    0 & F_1 & ~ \dots ~ & 0 \\
    \vdots & \vdots & & \vdots\\
    0 & 0 & ~ \dots ~ & F_{N_p-1}\\
    0 & 0 & ~ \dots ~ & 0
    \end{bmatrix}
\end{equation*}
Note that (\ref{eq:MPCdense}) is formulated in a purely quadratic form and one can use any of the available QP solvers available. The optimization is done over the predicted control inputs $\mathbf{U} = [\mathbf{u}_0^\top,\mathbf{u}_1^\top,\dots,\mathbf{u}_{N_p-1}^\top]^\top$. Importantly, note that the size of the $\mathbf{H}$ and that of the vector of constraints $\mathbf{c}$ is independent of the dimension of the state. This formulation, when extended to lifted systems with a lifted dimension $K$ of the state, proves very useful as the above said matrices are independent of $K$ and the matrices can, in fact, be precomputed offline before deploying the controller. One needs only to evaluate the nonlinear mapping or the lifting of state at each time step, thereby making the cost of computation inexpensive. In summary, once the data matrices in (\ref{eq:MPCdense}) are formed, the cost of solving the optimization problem is independent of the dimension of the state space and therefore, a nonlinear MPC problem can be solved as a linear MPC problem provided linear predictors of the form (\ref{eq:MPCdisc}) can be estimated using the Koopman operator theory. Section \ref{Chapter:Data} deals with such \textit{lifting} variables that can approximate nonlinear systems.
% It is possible to write the discrete-time version of the regulation cost function in Eq.~\ref{eq:Costfunc} over a finite horizon $N_p$ as
% % 
% \begin{equation}
%     J_p = \sum_{i=0}^{N_p-1} \mathbf{x}_{k+i}^\top \mathbf{Q} \mathbf{x}_{k+i} + \mathbf{u}_{k+i}^\top \mathbf{R}\mathbf{u}_{k+i}
% \end{equation}
% % 
% which can be written as,
% \begin{equation}
%     J_p = \mathbf{X}_{k}^\top \mathbf{\bar{Q}} \mathbf{X}_{k} + \mathbf{U}_{k}^\top \mathbf{\bar{R}}\mathbf{U}_{k} \;, \quad \quad k = [0,1,\dots,N_p-1]
% \end{equation}
% . This can further be formulated in a pure quadratic form by considering $\mathbf{w} = [\mathbf{X}_k\quad \mathbf{U}_k]^\top$ which results in
% % 
% \begin{equation}
%     J_p = \mathbf{W}^\top\begin{bmatrix}
%     \mathbf{\bar{Q}} & \\
%      & \mathbf{\bar{R}}
%     \end{bmatrix} \mathbf{W}
% \end{equation}
% % 
% The optimal control problem (OCP) for a LTI predictive control law can then defined as
% % 
% \begin{align}
% \label{eq:MPC1}
% \begin{split}
%     & \min_{\mathbf{U}_k} \mathbf{W}^\top\begin{bmatrix}
%     \mathbf{\bar{Q}} & \\
%      & \mathbf{\bar{R}}
%     \end{bmatrix} \mathbf{W} \;, \\
%     & \textup{subject to}\\
%     &\tilde{\mathbf{A}}\mathbf{W} + \tilde{\mathbf{b}} = \mathbf{0}\;, \\
%     &\textup{with}\\
%     &\tilde{\mathbf{A}} = [(\mathbf{\bar{A}} - \mathbf{I}) \quad \mathbf{\bar{B}}] ~ \textup{and} ~ \tilde{\mathbf{b}} = \mathbf{A}_0\mathbf{x}
% \end{split}
% \end{align}
% The Eqs.~\ref{eq:NstepComp} and \ref{eq:Nstepout} can be written in a quadratic form  and the optimization can be formulated as minimization of 



% % 
% where $\mathbf{Q} \in \mathbb{R}^{l\times l}$ is the penalty on the output state error and is positive semi-definite and $\mathbf{R} \in \mathbb{R}^{m\times m}$ is the penalty on the input and is positive definite. This is similar to the cost function defined in Eq. \ref{eq:Costfunc} except that the cost function here is evaluated over a finite time horizon defined by $N_p$ time steps. The cost function for the entire prediction horizon can consequently be written as,
% % 
% \begin{equation}
% \label{eq:MPC2}
%     \mathbf{J}_p = (\mathbf{R}_{k+1} - \mathbf{Y}_{k+1})^\top\mathbf{\bar{Q}}(\mathbf{R}_{k+1} - \mathbf{Y}_{k+1})^\top + \mathbf{U}_k^\top\mathbf{\mathbf{R}}\mathbf{U}_k \;, 
% \end{equation}\\
% % 
%  and is not to be confused with $\mathbf{R} = \mathbf{I}_{N_p} \otimes \mathbf{r} ~\in \mathbb{R}^{N_pl}$ which is the vector of reference trajectory. Substituting Eqs.~\ref{eq:NstepComp} and \ref{eq:Nstepout} in Eq.~\ref{eq:MPC2} and after some algebraic manipulations and taking the gradient of the cost function with respect to the optimization variable $\mathbf{U}_k$ and solving for the optimal control sequence $\mathbf{U}_k^{\ast}$ by setting the gradient to zero,  which is elaborately explained in \cite{MPCbook}, the final result can be presented as,
% % 
% \begin{equation}
%     \mathbf{U}_k^{\ast} = -(\mathbf{\bar{B}}^\top\mathbf{\bar{C}}^\top\mathbf{\bar{Q}}\mathbf{\bar{C}}\mathbf{\bar{B}} + \mathbf{\bar{R}})^{-1}~(\mathbf{\bar{B}}^\top\mathbf{\bar{C}}^\top\mathbf{\bar{Q}}^\top\mathbf{\bar{C}}\mathbf{\bar{A}}\mathbf{x}_k - \mathbf{\bar{B}}^\top\mathbf{\bar{C}}^\top\mathbf{\bar{Q}}^\top\mathbf{R}_{k+1}) \;.
% \end{equation}
% % 
% The above optimal control input sequence can be computed without any significant computational effort. However, the significance of MPC relies just not on the predictive capability but also on the ease of including constraints on the inputs and outputs.

% The general structure of the controller is shown below. 
% \begin{equation}
%     J = \sum_{i=0}^{N_p-1} \boldsymbol{e}_{k+i}^\top \mathbf{Q} \boldsymbol{e}_{k+i} + \boldsymbol{\Delta}\mathbf{u}_{k+i}^\top \mathbf{R}\boldsymbol{\Delta}\mathbf{u}_{k+i} \;, 
% \end{equation}
% where $\boldsymbol{e_{k+i}} = \mathbf{x}_{k+i} - \boldsymbol{r}_{k+i}$ is the deviation of the state from its reference, $\boldsymbol{\Delta}\mathbf{u}_{k+i}$ is the input increment and $N_p$ is the prediction horizon,  The model in -- needs to be augmented with the incremental value of input
% \begin{equation}
% \label{eq:MPCmodel}
%     \begin{bmatrix}
%     \mathbf{x}_{k+1} \\ \mathbf{u}_k
%     \end{bmatrix} = \begin{bmatrix}
%     \mathbf{A} & \mathbf{B} \\ \mathbf{0} & ~\mathbf{I}_m
%     \end{bmatrix}~\begin{bmatrix}
%     \mathbf{x}_k \\ \mathbf{u}_{k-1}
%     \end{bmatrix}~+~ \begin{bmatrix}
%     \mathbf{B} \\ ~\mathbf{I}_m 
%     \end{bmatrix} \boldsymbol{\Delta}\mathbf{u}_k \;.
% \end{equation}
% \textbf{Topics to be included in this section:}
% $\boldsymbol{e_{k+i}} = \boldsymbol{r}_{k+i} - \mathbf{Cx}_{k+i}$ is the deviation of the output state from its reference, 
% The optimal control problem (OCP) for the LTI predictive control law is defined as
% \begin{align}
%     & \min_{\Delta \mathbf{U}_k} \sum_{i=0}^{N_p-1} \boldsymbol{e}_{k+i}^\top \mathbf{Q} \boldsymbol{e}_{k+i} + \boldsymbol{\Delta}\mathbf{u}_{k+i}^\top \mathbf{R}\boldsymbol{\Delta}\mathbf{u}_{k+i} \;, \tag{5.10a}\label{eq:MPCcost} \\
%     & \textup{subject to} \notag\\
%     & \tilde{\mathbf{x}}_{k+j+1} = \tilde{\mathbf{A}}\tilde{\mathbf{x}}_{k+j} + \tilde{\mathbf{B}}\boldsymbol{\Delta}\mathbf{u}_{k+j} \;, \tag{5.10b}\label{eq:MPCmodel_const} \\
%     & \mathbf{u}_{k+j} = \mathbf{u}_{k-1} + \sum_{i=0}^j (\boldsymbol{\Delta}\mathbf{u})_{k+i} \in \mathcal{U} \;, \tag{5.10c}\label{eq:MPCinput_const} \\
%     & \tilde{\mathbf{x}}_{k+j} \in \mathcal{X}~ \textup{for} ~j \in [0,1,\dots,N-1] \;, \tag{5.10d}\label{eq:MPCstates}
% \end{align}
% where $\mathcal{U}$ is the constrained input set and $\mathcal{M}$ is the set of admissible states. The vector $\boldsymbol{\Delta}\mathbf{U}_k = [\boldsymbol{\Delta}\mathbf{u}_k^\top,\dots,\boldsymbol{\Delta}\mathbf{u}_{k+N-1}^\top]^\top$ represents the future inputs. Note that the model constraints (\ref{eq:MPCmodel_const}) are linear in the input increments, thus they can be substituted into the cost function by using an $N$ step ahead prediction equation. This will transform the optimal control problem into a quadratic program (QP), which can be solved fast and efficiently. An important observation is that the order of the model (\ref{eq:MPCmodel}), does not increase the problem complexity since the QP only has the inputs as decision variables. 
% \begin{itemize}
%     \item Overview of control in Koopman coordinates
% \end{itemize}